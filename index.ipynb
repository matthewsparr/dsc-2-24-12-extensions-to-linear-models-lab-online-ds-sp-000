{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts learned in this section, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with polynomial features/interactions\n",
    "- Perform regularization\n",
    "- Use AIC and BIC to select the best value for the regularization parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a Baseline Boston Housing Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston housing data set, use all the predictors in their scaled version (using `preprocessing.scale`. Look at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation this time and use the $R^2$ score to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target      CRIM        ZN     INDUS      CHAS       NOX        RM  \\\n",
       "0    24.0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217  0.413672   \n",
       "1    21.6 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.194274   \n",
       "2    34.7 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262  1.282714   \n",
       "3    33.4 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284  1.016303   \n",
       "4    36.2 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284  1.228577   \n",
       "\n",
       "        AGE       DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0 -0.120013  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.367166  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2 -0.265812  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3 -0.809889  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4 -0.511180  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "boston = load_boston()\n",
    "reg = LinearRegression()\n",
    "\n",
    "y = pd.DataFrame(boston.target,columns = [\"target\"])\n",
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = X.columns)\n",
    "\n",
    "df = pd.concat([y,X_scaled], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176324491383005"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(reg, X_scaled, y, scoring=\"r2\", cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold classification and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "You've created code for this before in the interactions lab, yet this time, you have scaled the variables so the outcomes may look different. \n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interactions: [('RM', 'LSTAT', 0.783), ('RM', 'TAX', 0.775), ('RM', 'RAD', 0.77), ('RM', 'PTRATIO', 0.764), ('INDUS', 'RM', 0.757), ('NOX', 'RM', 0.746), ('RM', 'AGE', 0.742)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "combinations = list(combinations(boston.feature_names, 2))\n",
    "\n",
    "interactions = []\n",
    "data = X_scaled.copy()\n",
    "for comb in combinations:\n",
    "    data[\"interaction\"] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(reg, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "    if score > baseline: interactions.append((comb[0], comb[1], round(score,3)))\n",
    "            \n",
    "print(\"Top 7 interactions: %s\" %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>-0.444930</td>\n",
       "      <td>-0.275757</td>\n",
       "      <td>-0.406574</td>\n",
       "      <td>-0.603547</td>\n",
       "      <td>-0.532772</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.095668</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>-0.168607</td>\n",
       "      <td>-0.058883</td>\n",
       "      <td>-0.115279</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>-1.550451</td>\n",
       "      <td>-1.266461</td>\n",
       "      <td>-1.113245</td>\n",
       "      <td>-0.388783</td>\n",
       "      <td>-0.761138</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>-1.383713</td>\n",
       "      <td>-1.124148</td>\n",
       "      <td>-0.765197</td>\n",
       "      <td>0.114875</td>\n",
       "      <td>-1.328183</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>-1.261136</td>\n",
       "      <td>-1.358947</td>\n",
       "      <td>-0.925023</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>-1.605599</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562 -0.444930   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439 -0.095668   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727 -1.550451   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517 -1.383713   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501 -1.261136   \n",
       "\n",
       "     RM_TAX    RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0 -0.275757 -0.406574   -0.603547 -0.532772 -0.059659 -0.049646  \n",
       "1 -0.191813 -0.168607   -0.058883 -0.115279 -0.143814  0.071331  \n",
       "2 -1.266461 -1.113245   -0.388783 -0.761138 -0.949544 -0.340960  \n",
       "3 -1.124148 -0.765197    0.114875 -1.328183 -0.848901 -0.823092  \n",
       "4 -1.358947 -0.925023    0.138869 -1.605599 -1.026210 -0.628023  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter = X_scaled.copy()\n",
    "ls_interactions = sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7]\n",
    "for inter in ls_interactions:\n",
    "    df_inter[inter[0]+\"_\"+inter[1]] =df[inter[0]]*df[inter[1]]\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of 2, 3 and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 polynomials: [('RM', 4, 0.8), ('RM', 2, 0.782), ('LSTAT', 4, 0.782), ('RM', 3, 0.781), ('LSTAT', 3, 0.774), ('LSTAT', 2, 0.772), ('DIS', 3, 0.737), ('DIS', 2, 0.732), ('DIS', 4, 0.731), ('TAX', 4, 0.724)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomials = []\n",
    "c = df.drop('target', axis=1).columns\n",
    "for col in c:\n",
    "    for degree in [2,3,4]:\n",
    "        data = X_scaled.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X = poly.fit_transform(df[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X)], axis = 1)\n",
    "        score = np.mean(cross_val_score(reg, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "        if score > baseline: polynomials.append((col, degree, round(score,3)))\n",
    "print(\"Top 10 polynomials: %s\" %sorted(polynomials, key=lambda poly: poly[2], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "ZN         0.723\n",
       "INDUS      0.723\n",
       "CHAS       0.718\n",
       "NOX        0.721\n",
       "RM         0.800\n",
       "AGE        0.722\n",
       "DIS        0.737\n",
       "RAD        0.719\n",
       "TAX        0.724\n",
       "PTRATIO    0.721\n",
       "B          0.720\n",
       "LSTAT      0.782\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "polynom = pd.DataFrame(polynomials)\n",
    "polynom.groupby([0], sort=False)[2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding Polynomial terms?\n",
    "RM and LSTAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two feature, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for col in [\"RM\", \"LSTAT\"]:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X = poly.fit_transform(df[[col]])\n",
    "    colnames= [col, col+\"_\"+\"2\", col+\"_\"+\"3\", col+\"_\"+\"4\"]\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1),pd.DataFrame(X, columns=colnames)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>0.171124</td>\n",
       "      <td>0.070789</td>\n",
       "      <td>0.029284</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>1.156834</td>\n",
       "      <td>-1.244247</td>\n",
       "      <td>1.338266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.037743</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>0.242497</td>\n",
       "      <td>-0.119415</td>\n",
       "      <td>0.058805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>1.645354</td>\n",
       "      <td>2.110519</td>\n",
       "      <td>2.707191</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>1.461022</td>\n",
       "      <td>-1.765977</td>\n",
       "      <td>2.134585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>1.032871</td>\n",
       "      <td>1.049709</td>\n",
       "      <td>1.066822</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>1.853728</td>\n",
       "      <td>-2.523882</td>\n",
       "      <td>3.436308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>1.509401</td>\n",
       "      <td>1.854414</td>\n",
       "      <td>2.278290</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>1.053705</td>\n",
       "      <td>-1.081630</td>\n",
       "      <td>1.110295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO    ...       NOX_RM    RM_AGE        RM  \\\n",
       "0 -0.982843 -0.666608 -1.459000    ...    -0.059659 -0.049646  0.413672   \n",
       "1 -0.867883 -0.987329 -0.303094    ...    -0.143814  0.071331  0.194274   \n",
       "2 -0.867883 -0.987329 -0.303094    ...    -0.949544 -0.340960  1.282714   \n",
       "3 -0.752922 -1.106115  0.113032    ...    -0.848901 -0.823092  1.016303   \n",
       "4 -0.752922 -1.106115  0.113032    ...    -1.026210 -0.628023  1.228577   \n",
       "\n",
       "       RM_2      RM_3      RM_4     LSTAT   LSTAT_2   LSTAT_3   LSTAT_4  \n",
       "0  0.171124  0.070789  0.029284 -1.075562  1.156834 -1.244247  1.338266  \n",
       "1  0.037743  0.007332  0.001425 -0.492439  0.242497 -0.119415  0.058805  \n",
       "2  1.645354  2.110519  2.707191 -1.208727  1.461022 -1.765977  2.134585  \n",
       "3  1.032871  1.049709  1.066822 -1.361517  1.853728 -2.523882  3.436308  \n",
       "4  1.509401  1.854414  2.278290 -1.026501  1.053705 -1.081630  1.110295  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061116489237061"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "full_model = np.mean(cross_val_score(reg, df_inter, y, scoring=\"r2\", cv=crossvalidation))\n",
    "full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've learned that, when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter alpha of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xd4FVX6wPHvm0JCC11aQoKAlMRQgkAAEYFVZBXRFdsqWHERVlcFFH/LLrqWXcvqoqJgBXRBxYauBVCaGkC69CKBBELvJUCS8/vjzE1ukhtyA7mZlPfzPPNk7syZmffOvXfezJyZc8QYg1JKKZVXkNsBKKWUKp00QSillPJJE4RSSimfNEEopZTySROEUkopnzRBKKWU8kkTRBkgIvVFZL6IHBWRF92OJy8RuVRENpSCOJqIyDERCS7Gdb4hImOKa31e6xUReVdEDorI4uJef3ETkWQR6eNHuRgRMSISUozbLvZ1Oust9u9LeaMJwiX+/uAcQ4B9QIQx5pEAhuUX58fa3PPaGLPAGNPSzZicOLYbY6oZYzIBRGSuiNxznuv8kzHmH8UTYS7dgd8BkcaYTgFYv8oj728u7/dF5acJomyIBtaac3iqsbj/6yqtAvE+A/yfZTSQbIw5XtQFK8pnqkoBY4wOLgxAMtDHGb8D+BF4ATgIbAWucua9B5wBTgPHgD5AGPAysNMZXgbCnPI9gVTgUWAXMMVr2ihgD5AGDAD6ARuBA8DjXrF1ApKAQ07ZV4FKzrz5gAGOO/Hc5Fm/1/KtgbnO8muA/l7z3gNeA/4HHAUWAc3Osp8qAy8C24DDzn6qDMQ4cdwNbHfi8kwLAZ4GMoF0J85XnfW1AmY573kDcGOe2F4HvnbeXx9n2lNeZe4FNjvLzwAaec0zwJ+ATc7n+BogPt7T3U5cmU5sT/i57mHOurf6WKfnvd8JpDjb/xNwCbDK+Sxe9SofBPzV2a97gMlADa/5tzvz9gP/R+7vaxDwGLDFmf8RUDtPHCEFfJ6PAjucz34D0Luo6wRqAG9jv5s7gKeA4Dyf0TpnG2uBDtjfQRZw0tnno3yst5Gz3w84n8O9Xusc68Q02VnvGqCj28eRgB+n3A6gog7kTxBnnC92MDAUe+AXZ/575D5IPQksBC4A6gE/A/9w5vUEMoB/YRNJZa9pfwNCne3sBf4LVAdisQesC511JABdsAfaGOfH9hev7RugudfrnjgJwln/ZuBxoBLQy/lBtfR6LwewSSgE+ACYdpb99Bo22TR29k1X5315ftyTgarkThqeH/xc4B6vdVXFHjzvdLbdAXvpLtYrtsNAN+wBK9x73zvvZZ+zXBjwCjA/z375CqgJNHH2cd8C3tcdwI9er/1Z9yygNlDZx/o87/0NJ+4rnM/0c+z3pDE2EVzmlL/L+ZwuBKoBnwJTnHltsAfRHk4s/8Z+fzzf179gv3+RzvwJwNQ8ceRLEEBLZ/838irbrKjrdN7TBOfzvABYDNznzBuITRqXAAI0B6Lz/uYKWO88YLyz/9o5n58ngY119mc/7PfwWWCh28eRgB+n3A6gog7kTxCbveZVcb64DZzX75E7QWwB+nm9vhJ7uQLswfo0EO41vyf2P6dg53V1Z/2dvcosBQYUEOtfgM+8Xp8tQVyKPXMJ8po/FRjr9V7e8prXD1hfwHaDnLjb+pjn+XFf6GNaQQniJmBBnvVMAP7uFdvkPPOz9z32v9bnvOZVwyb2GK/90t1r/kfAYwW8tzvInSD8WXevs3yfPO+9sde0/cBNXq8/wUn0wPfA/V7zWjrbC8H+IzHNa15V5zvl+b6uwzlwOq8bei2b6zPIE2NzbJLqA4TmmefXOoH6wCm8kiRwCzDHGf8OeLCw31ze7wsQhT2jq+41/1ngPWd8LDDba14b4GRxHQ9K66B1EKXHLs+IMeaEM1qtgLKNsKf/HtucaR57jTHpeZbZb3Iq4046f3d7zT/p2Z6IXCQiX4nILhE5AjwD1PXzfTQCUowxWXnia+z1epfX+Amv7T7u3FVyTETecLYZjk2IBUnxMy6w1/07i8ghzwD8EWjg5/py7XdjzDHsQbjQ9+YHf9btz3vN+5n6/Izzbs8Z9xyAG3lvy9h6kv1eZaOBz7z24TrswbX+2QIzxmzG/rMxFtgjItNExPO99Xed0diz1DSvshOwZxJgD/Rn+74UpBFwwBhz1GtaYd/b8PJeH6QJomzaif2heDRxpnmY81z/68B6oIUxJgJ7uUiKEFuUiHh/t5pgT/vPyhjzjLF3lVQzxvwJe8klHWh2tsWKMC8FmGeMqek1VDPGDPVzfbn2u4hUBergx3vzgz/rPt/PtcDtYT+jDGxCScMeaD2xVHFi8UjB1pF578dwY4w/n/F/jTHdnW0b7KXQoqwzBXsGUderXIQxJtZrfkHfl8I+29oiUt1rml/f2/JME0TZNBX4q4jUE5G62EsC7xfj+qsDR4BjItIKWyfibTf22rUvi7AVvKNEJFREegLXANOKGoRzFvIO8G8RaSQiwSKSKCJhfq4ib5xfAReJyO1ObKEicomItPZzff8F7hSRdk4MzwCLjDHJfi7v1rp9mQo8JCJNRaSas70PjTEZwHTgahHpLiKVsHVe3seKN4CnRSQawPkeXlvYBkWkpYj0ct5fOvaMxnNW69c6jTFpwEzgRRGJEJEgEWkmIpc5Rd4CRohIgvOsSXPPOjnL99YYk4Kty3tWRMJFJB57M8EHhb2v8kwTRNn0FLAEe3fKr8AyZ1pxGQHciq1cfhP4MM/8scAk5xT/Ru8ZxpjTQH/gKuwZwHhgkDFm/XnE8ivwC7Zy+1/4/739D3CD8zDaOOfywRXAzdj/GHeRU5lfKGPM98AY7LX8NOx/qjf7/1bcWXcB3sHe2TMfe9dcOvBnJ5Y12Dum/uvEchB7F5zHf7B3+8wUkaPYyuXOfmwzDPgn9nuxC3tZ6PFzWOcg7A0Qa53YpmPrLDDGfIy9g+2/2O/v59iKfbB1Cn91vrcjfKz3Fmy9xE7gM2zd1Cw/3le55blLRimllMpFzyCUUkr5pAlCKaWUT5oglFJK+aQJQimllE9l+iGPunXrmpiYGLfDKBeWLrV/ExLcjaOiWLrT7vCERrrDVclbunTpPmNMvcLKlem7mDp27GiWLFnidhjlgjiPwZXhr0OZIk/YHW7+rjtclTwRWWqM6VhYOb3EpJRSyidNEEoppXzSBKGUUsqnMl1JrZQqHc6cOUNqairp6XkbEVZuCg8PJzIyktDQ0HNaXhOEUuq8paamUr16dWJiYhDxt+FfFUjGGPbv309qaipNmzY9p3XoJSal1HlLT0+nTp06mhxKERGhTp0653VWpwlCKVUsNDmUPuf7mWiCUEop5VNAE4SIJIvIryKyQkSWONNqi8gsEdnk/K3lTBcRGScim0VklYh0CFRcD77wE9Wb/8oNj8wP1CaUUi747LPPEBHWr7fdjyQnJxMXF5c9f/HixfTo0YOWLVvSqlUr7rnnHk6cOFHQ6iq8kjiDuNwY087rqb3HgO+NMS2wHac/5ky/CmjhDEOw3V4GxP6DGRzbcjHLl2odvVLlydSpU+nevTvTpuXvwHD37t0MHDiQf/3rX2zYsIF169bRt29fjh496mNNCty5xHQtMMkZnwQM8Jo+2VgLgZoi0jAQAXRuZ7ud3Z1cKxCrV0q54NixY/z000+8/fbbPhPEa6+9xuDBg0lMTATs9fkbbriB+vXrl3SoZUag/4U22C4EDTDBGDMRqO/0K4sxJk1ELnDKNsZ2OO6R6kxL816hiAzBnmHQpEmTcwqqVyebd47vbEJmpiE4WCvXlCpOnramfJlw9QSGJAwBYOLSidz31X0Fli1KW1Wff/45ffv25aKLLqJ27dosW7aM2rVrZ89fvXo1gwcP9nt9KvBnEN2MMR2wl4+GiUiPs5T19Y3K9+0wxkw0xnQ0xnSsV6/Qxgh9atOkAVJtN5ypysqNB85pHUqp0mXq1KncfLPtxvvmm29m6tSpLkdU9gX0DMIYs9P5u0dEPgM6AbtFpKFz9tAQ2OMUTwWivBaPxHYeXuxEhGqNUji6sT5zfkmjQ+s6gdiMUhWWv//5D0kYkn02cT7279/PDz/8wOrVqxERMjMzERHuv//+7DKxsbEsXbqUa6+99ry3V1EE7AxCRKqKSHXPOHAFsBqYAXjO8wYDXzjjM4BBzt1MXYDDnktRgdDgwoMALF5xPFCbUEqVkOnTpzNo0CC2bdtGcnIyKSkpNG3alNTU1Owyw4cPZ9KkSSxatCh72vvvv8+uXbvcCLlMCOQZRH3gM+dBjRDgv8aYb0XkF+AjEbkb2A4MdMp/DfQDNgMngDsDGBv9+1Xi+7B5XJZYN5CbUUqVgKlTp/LYY4/lmvaHP/yBZ555Jvt1/fr1mTZtGiNGjGDPnj0EBQXRo0cPrr/++pIOt8zQDoMUoB0GlbTy1mHQunXraN26tdthKB98fTbaYZBSSqnzUqETxLTZaxn6zE/s3X/G7VCUUqrUqdCPEt9x70lOJXcjsU0KgwZEFb6AUkpVIBX6DKJutL3D9qdlB12ORCmlSp8KnSBiWth20n9dnelyJEopVfpU6AQRH2uvsCVvDnc5EqWUKn0qdILo1sG207Jv2wWFlFRKlVUxMTHs27fvvMuczciRI4mNjWXkyJHnvA6ABx98kMaNG5OVlZU97b333mP48OHZrydPnkxcXByxsbG0adOGF1544by2eTYVupL60vhoCD3OmSN1OHAAvNr1Ukopv02YMIG9e/cSFhbmV/mMjAxCQnIffrOysvjss8+Iiopi/vz59OzZM99y33zzDS+//DIzZ86kUaNGpKenM2XKlOJ4Cz5V6DOIqBqNCaq3EULS+XWDtgmvVFk2YMAAEhISiI2NZeLEifnmJycn06pVKwYPHkx8fDw33HBDrs6CXnnlFTp06MDFF1+c3eHQ4sWL6dq1K+3bt6dr165s2LAh33r79+/P8ePH6dy5Mx9++CHbtm2jd+/exMfH07t3b7Zv3w7AHXfcwcMPP8zll1/Oo48+mm89c+bMIS4ujqFDhxbY0OCzzz7LCy+8QKNGjQAIDw/n3nvvLfrO8lOFPoMQEZYtqE/rqFAqhWo9hFLF4WxNfZ+Pwp46f+edd6hduzYnT57kkksu4Q9/+AN16uRuiHPDhg28/fbbdOvWjbvuuovx48czYsQIAOrWrcuyZcsYP348L7zwAm+99RatWrVi/vz5hISEMHv2bB5//HE++eSTXOucMWMG1apVY8WKFQBcc801DBo0iMGDB/POO+/wwAMP8PnnnwOwceNGZs+eTXBwcL74p06dyi233MK1117L448/zpkzZwgNDc1VZvXq1SQkJBRtx52HCn0GAdD2wkZUCs3/YSmlypZx48bRtm1bunTpQkpKCps2bcpXJioqim7dugFw22238eOPP2bP87TJlJCQQHJyMgCHDx9m4MCBxMXF8dBDD7FmzZpC40hKSuLWW28F4Pbbb8+1jYEDB/pMDqdPn+brr79mwIABRERE0LlzZ2bOnOn/mw+QCn0GoZQqfm60LzV37lxmz55NUlISVapUoWfPnqSnp+crJyIFvvbUHwQHB5ORkQHAmDFjuPzyy/nss89ITk72WS9QGO9tVK1a1WeZb7/9lsOHD3PxxRcDcOLECapUqcLvf//7XOU8TZb36tWryHGciwp/BvHNiqVUu3A1taJTCi+slCqVDh8+TK1atahSpQrr169n4cKFPstt376dpKQkIKf/6sLW27hxY8DeTeSPrl27Znd5+sEHHxS6DU8sb731FsnJySQnJ7N161ZmzpyZq44EYPTo0YwaNSq7ifJTp04xbtw4v+I6FxU+QdStE8Tx7S04tD2KY8fcjkYpdS769u1LRkYG8fHxjBkzhi5duvgs17p1ayZNmkR8fDwHDhxg6NChZ13vqFGjGD16NN26dSMz078HaseNG8e7775LfHw8U6ZM4T//+c9Zy584cYLvvvsu19lC1apV6d69O19++WWusv369WPYsGH06dOH2NhYEhISss92AqHCN/d9/PRxqkX9BnsuJmlRBl06Vcyrbtrcd8nS5r5LXnJyMldffTWrV692O5QSpc19n4eqlapSuVEyAAuW7Hc3GKWUKkUqfIIAaBDjdD+6Up+FUKq8iomJqXBnD+cr4AlCRIJFZLmIfOW8fk9EtorICmdo50wXERknIptFZJWIdAh0bB4tWtr+INatLaktKqVU6VcSZxAPAuvyTBtpjGnnDCucaVcBLZxhCPB6CcQGQPuL7UNyqb9VL6lNKqVUqRfQBCEikcDvgbf8KH4tMNlYC4GaItIwkPF5DOjWhg7XzeOO4WklsTmllCoTAn3LzsvAKCDvv+ZPi8jfgO+Bx4wxp4DGgPfDCKnOtFxHbREZgj3DoEmTJsUSZJeY9iz9tFhWpZRS5UbAziBE5GpgjzFmaZ5Zo4FWwCVAbcDTapWvBlzy3QNojJlojOlojOlYr1694gxZKVVGBQcH065dO9q2bUuHDh34+eefAXtra1xcXHa5xYsX06NHD1q2bEmrVq2455578j2MpnIE8gyiG9BfRPoB4UCEiLxvjLnNmX9KRN4FRjivUwHvjqEjgZ0BjC+XmUvXM/2bfVwWdxF/HKD9QyhVllSuXDm7sbzvvvuO0aNHM2/evFxldu/ezcCBA5k2bRqJiYkYY/jkk084evQoVapUcSPsUi9gZxDGmNHGmEhjTAxwM/CDMeY2T72C2AZKBgCe+85mAIOcu5m6AIeNMSVWKTDmvVm8OaY748brfxNKlWVHjhyhVq1a+aa/9tprDB48mMTERMC2kXTDDTdQv379kg6xzHDjseEPRKQe9pLSCuBPzvSvgX7AZuAEcGdJBhXXJoTFwNZNlUtys0qVS3KWFr8nTIAhQ+z4xIlw330Fl/X3yf6TJ0/Srl070tPTSUtL44cffshXZvXq1QwePNi/FSqghBKEMWYuMNcZ99kMobFtfgwriXh8SWxfi3eAfSl1yMiAkIrZ4oZSZZL3JaakpCQGDRqkD8UVA32S2tE2qhnUSMZkhuCj0yilVBEYU/DgOXsAO362suciMTGRffv2sXfv3lzTPU1lK/9pgnC0rNsSIm0TwfPmZRVSWilVWq1fv57MzMx8vckNHz6cSZMmsWjRouxp77//fnbT2So/TRCOiLAIIlraU9Rvvj/ucjRKqaLw1EG0a9eOm266iUmTJuXrua1+/fpMmzaNESNG0LJlS1q3bs2CBQuIiIhwKerST6+0e2mfeJh5M9I5mn6c/M/2KaVKq4L6asjbQF9iYiILFiwoqbDKPE0QXj7605NUuT+EalUauB2KUkq5ThOElwuq6ZPZSinloXUQPhxPP8X6TafcDkMppVylCSKPIe8/RbWa6XTtnqXdbyqlKjRNEHk0bmwg+DQH91Rmyxa3o1FKKfdogsjjsqaXQvR8AObOdTcWpZRykyaIPDo37kxQU3sb3KwfTrscjVLqfMXExLBv377zLnM2I0eOJDY2lpEjR57T8nPnzqVGjRq0a9eO+Ph4+vTpw549ewB47733GD58eHbZyZMnExcXR2xsLG3atOGFF14457gLowkij8qhlYnvdBCAH+Zkaj2EUqpQEyZMYNmyZTz//PN+lc/IyMg37dJLL2XFihWsWrWKSy65hNdeey1fmW+++YaXX36ZmTNnsmbNGpYtW0aNGjXOO/6CaILwoW/XSKi8n327KrN1q9vRKKX8MWDAABISEoiNjWXixIn55icnJ9OqVSsGDx5MfHw8N9xwQ67Ogl555RU6dOjAxRdfzPr16wHbwVDXrl1p3749Xbt2ZYOPhtr69+/P8ePH6dy5Mx9++CHbtm2jd+/exMfH07t3b7Zv3w7AHXfcwcMPP8zll1/Oo48+mm89HsYYjh496rPJ8meffZYXXniBRo0aARAeHs69995btB1VBJogfPCuh9CHLpUqGpHADIV55513WLp0KUuWLGHcuHHs378/X5kNGzYwZMgQVq1aRUREBOPHj8+eV7duXZYtW8bQoUOzL9u0atWK+fPns3z5cp588kkef/zxfOucMWNGdmuyN910E8OHD2fQoEGsWrWKP/7xjzzwwAPZZTdu3Mjs2bN58cUX861nwYIFtGvXjiZNmjB79mzuuuuufGVWr15NQkJC4TujmGiC8KFbVDfGjhX+9+N2br/d7WiUUv4YN24cbdu2pUuXLqSkpLBp06Z8ZaKioujWrRsAt912Gz/++GP2vOuvvx6AhIQEkpOTATh8+DADBw4kLi6Ohx56iDVr1hQaR1JSErfeeisAt99+e65tDBw4MF8bUR6eS0wpKSnceeedjBo1yr83HkCaIHyoHladv980gH7dmhCke0ipIjlb893nM5zN3LlzmT17NklJSaxcuZL27duTnp6er5zkORXxfh0WFgbY/q09dQRjxozh8ssvZ/Xq1Xz55Zc+11kY721UrVrVr2X69+/P/Pnz800v6SbLA374E5FgEVkuIl85r5uKyCIR2SQiH4pIJWd6mPN6szM/JtCxKaXKh8OHD1OrVi2qVKnC+vXrWbhwoc9y27dvJykpCYCpU6fSvXv3QtfbuHFjwN5N5I+uXbsybdo0AD744INCt+HLjz/+SLNmzfJNHz16NKNGjcpuovzUqVOMGzeuyOv3V0n8f/wgsM7r9b+Al4wxLYCDwN3O9LuBg8aY5sBLTjnX7Dy6kytGTKF+y994/303I1FKFaZv375kZGQQHx/PmDFj6NKli89yrVu3ZtKkScTHx3PgwAGGDh161vWOGjWK0aNH061btwJbjM1r3LhxvPvuu8THxzNlyhT+85//+LWcpw6ibdu2TJkyxWc9Rb9+/Rg2bBh9+vQhNjaWhIQEn3dEFRtjTMAGIBL4HugFfIXth3ofEOLMTwS+c8a/AxKd8RCnnJxt/QkJCSZQ9h7fa7jyLwaMGTQ4I2DbKS08J/KqZDAWw9jys8PXrl3rdgiF2rp1q4mNjXU7jBLn67MBlhg/juGBPoN4GRgFeLpoqwMcMsZ4Ul4q0NgZbwykADjzDzvlcxGRISKyRESW5O1SsDjVrVKXC9ulAjD7hzMB245SSpVWAUsQInI1sMcY412j4utmNePHvJwJxkw0xnQ0xnSsVy+wzXP3SawHYYfYmRKOcyuzUqqMytt5kCpcIM8gugH9RSQZmIa9zPQyUFNEPP1QRAI7nfFUIArAmV8DOBDA+ArV88JLIdo+CDFvnpuRKFX6GW12oNQ5388kYAnCGDPaGBNpjIkBbgZ+MMb8EZgD3OAUGwx84YzPcF7jzP/BuPyNuzT6UoiZC8CcOVlnL6xUBRYeHs7+/fs1SZQixhj2799PeHj4Oa/DjR7lHgWmichTwHLgbWf628AUEdmMPXO42YXYcomMiKTxxVvYMRNmzTkDhLkdklKlUmRkJKmpqQSyXlAVXXh4OJGRkee8fIkkCGPMXGCuM/4b0MlHmXRgYEnEUxR3X5XA5xsXMPj3LTCmgV+P/CtV0YSGhtK0aVO3w1DFTPukLsQTvcfwRG+3o1BKqZKnDUkopZTySROEH9ambeHep+Yy/JHDboeilFIlRhOEH8bOH8Nb/0jgtX/XYOfOwssrpVR5oAnCDz0v7A5NbJO9+jyEUqqi0AThhx7RPSDaZoa5c/U+b6VUxaAJwg9t6rUhouVyAGbP0XaZlFIVgyYIPwRJED0Sq0LoMX7bVAmnKXallCrXNEH4qeeF3aDJT4DWQyilKgZNEH7qEd2DkObzqNdyM2Ha4oZSqgLQJ6n9lNAogeP/a0ul4Epuh6KUUiVCzyD8FCRBmhyUUhWKJogiOnXmDDN/2sWmTW5HopRSgaUJoghW7V5F9Wue5MruDfCzH3KllCqzNEEUwUV1LsJE2Seqv5+TUUhppZQq2zRBFEF4SDidLwmCkJOsXxvCvn1uR6SUUoGjCaKIejZPhMgkAObPdzkYpZQKoIAlCBEJF5HFIrJSRNaIyBPO9PdEZKuIrHCGds50EZFxIrJZRFaJSIdAxXY+ekT3yO6neu5cV0NRSqmACuQZxCmglzGmLdAO6CsiXZx5I40x7ZxhhTPtKqCFMwwBXg9gbOcsMTKRoKa2HmLO3EyXo1FKqcAJWIIw1jHnZagznK0p1GuByc5yC4GaItIwUPGdq+ph1WnX8RQEp7M1OYvjx92OSCmlAiOgdRAiEiwiK4A9wCxjzCJn1tPOZaSXRMTTcEVjIMVr8VRnWt51DhGRJSKyZO/evYEMv0CvXvMCXy1I5cD+YKpWdSUEpZQKuIAmCGNMpjGmHRAJdBKROGA00Aq4BKgNPOoUF1+r8LHOicaYjsaYjvXq1QtQ5GeXGJXI7xObUylU6/iVUuWXX0c4EbleRDaJyGEROSIiR0XkiL8bMcYcAuYCfY0xac5lpFPAu0Anp1gqEOW1WCRQ6jv4PH3a7QiUUiow/P0X+DmgvzGmhjEmwhhT3RgTcbYFRKSeiNR0xisDfYD1nnoFERFgALDaWWQGMMi5m6kLcNgYk3YO76lEvJT0MjViFxJRI5ODB92ORimlip+/CWK3MWZdEdfdEJgjIquAX7B1EF8BH4jIr8CvQF3gKaf818BvwGbgTeD+Im6vRG0+sIkjx05zKj2YBQvcjkYppYqfv819LxGRD4HPsbevAmCM+bSgBYwxq4D2Pqb3KqC8AYb5GY/rekT3YHzMXNjeg7lzoX9/tyNSSqni5W+CiABOAFd4TTNAgQmivLs0+lKImQjzYe48g+86dqWUKrv8ShDGmDsDHUhZ06h6Iy6M38NvQadZsTyUQ4egZk23o1JKqeLj711MkSLymYjsEZHdIvKJiEQGOrjSrmfzTtB4McYIP/7odjRKKVW8/K2kfhd7l1Ej7MNrXzrTKjRtl0kpVZ75myDqGWPeNcZkOMN7gDtPqZUilze9nBtvgj8/vZwHHnA7GqWUKl7+VlLvE5HbgKnO61uA/YEJqexoUqMJHw77q9thKKVUQPh7BnEXcCOwC0gDbnCmKaWUKqf8vYtpO6B3+vtw8ORBXv/fj8z6uCnXdYvTS01KqXLjrAlCREYZY54TkVfw3XBehT8cph1L4/9VwQ+PAAAgAElEQVS+eBU++o4TyYYHHtDnIZRS5UNhZxCe5jWWBDqQsqp13dbUvmgDBySDpUuDOXoUqld3OyqllDp/Z00QxpgvRSQYiDPGjCyhmMoUEaHHRe35vNESMnd04aefoG9ft6NSSqnzV2gltTEmE0gogVjKrB5NekDMPADmzXM5GKWUKib+3sW0XERmiMjtTt8Q14vI9QGNrAzRB+aUUuWRv89B1MY+9+DdEmuFbqzPW9sGbanWbBXHJJMlS4I4dkyoVs3tqJRS6vxoY33FICQohN6tL+HnxJlceXFHTp6spwlCKVXm+ZUgROQi4HWgvjEmTkTisT3MPVXIohXGZzd9htyst7gqpcoPf+sg3gRGA2cguzOgm8+2gIiEi8hiEVkpImtE5AlnelMRWeT0cf2hiFRypoc5rzc782PO9U25wfagqpRS5Ye/CaKKMWZxnmkZhSxzCuhljGkLtAP6On1N/wt4yRjTAjgI3O2Uvxs4aIxpDrzklCtTMrMy+eLntbwyPp0TJ9yORimlzo+/CWKfiDTDeZpaRG7AtslUIGMdc16GOoPBVnRPd6ZPAgY449c6r3Hm95Yy9m/5tdOuZcANJ3lgWDhJSW5Ho5RS58ffBDEMmAC0EpEdwF+APxW2kIgEi8gKYA8wC9gCHDLGeM4+UrH9S+D8TQFw5h8G6vhY5xARWSIiS/bu3etn+CUjoWGC3u6qlCo3/E0QxhjTB9sHRCtjTHd/ljXGZBpj2gGRQCegta9izl9fZwu+2n+aaIzpaIzpWK9e6eqS4tLoSyHaPimnCUIpVdb5myA+ATDGHDfGHHWmTT9L+VyMMYeAuUAXoKaIeO6eigR2OuOpQBSAM78GcMDfbZQGiZGJBDdNAsli8WKj9RBKqTLtrAlCRFqJyB+AGt5PUIvIHUB4IcvWE5GaznhloA+28b852P4kAAYDXzjjM5zXOPN/MMbkO4MozapWqkrHC5tB/ZWcPi0sXOh2REopde4Kew6iJXA1UBO4xmv6UeDeQpZtCExyGvsLAj4yxnwlImuBaSLyFLAceNsp/zYwRUQ2Y88cznobbWnVI7oHi2Lmwq72zJsHvXoVuohSSpVKhbXm+gXwhYgkGmOKdF+O86xEex/Tf8PWR+Sdng4MLMo2SqMe0T14PvotgpYN5fjxs55kKaVUqeZXh0HArSJyS9752mFQfj1jerL4uSji3gulsuYHpVQZph0GFbNqlapxSZO2boehlFLnTTsMCqDTpw379gmNGrkdiVJKFZ12GBQAq/esJn70/VSJSOe229yORimlzo2//UEsF5EZwMfAcc9EY4z2B+FD3Sp1+TXzIzg1nqQkw6lTQliY21EppVTR+PugnHeHQdc4w9WBCqqsa1CtARc1qQMX/Ep6urA4bzOHSilVBvibIIKAh4wxdzqdBz0cwJjKBdtP9VwAhg6FXbvcjUcppYrK3wQR7zSXAYAx5iA+nnFQOS6NvjQ7QaxZA1deCRmFNZCulFKliN9nECJSy/NCRGrjf/1FhdQjugdc9CVhiW8CsG2bTRRKKVVW+HuQfxH4WUSmY1tYvRF4OmBRlQPRNaKJqt2AlCuHMG1sTy6Lb0GDBm5HpZRS/vMrQRhjJovIEmwltQDXG2PWBjSyMk5E+Ntlf6NScCWuuKgutSq7HZFSShWN35eJnISgSaEI7ulwT67XZ87A+PHQqRMkJroUlFJK+UnrEUqIMYZXXhEeeQQSEmDxYgjytwZIKaVcoIeoAPvt4G/c/tntjJw1kvvug8aNYelSmDSp8GWVUspNmiAC7HD6Yd5f9T7vrXiPSuFn+Ne/7PTRo+HIEXdjU0qps9EEEWDtGrSjTb027D+5n9m/zebWW6FrV9i9G57W+8CUUqVYwBKEiESJyBwRWScia0TkQWf6WBHZISIrnKGf1zKjRWSziGwQkSsDFVtJEhFuibNdaUxdPRUR+M9/7LyXXoJNm1wMTimlziKQZxAZwCPGmNZAF2CYiLRx5r1kjGnnDF8DOPNuBmKBvsB4p6nxMu/mONt76mfrP+PkmZN07Ah33mnvapowweXglFKqAAFLEMaYNGPMMmf8KLbzocZnWeRaYJox5pQxZiuwGR9dk5ZFzWs3p2Ojjhw7fYwZG2YA8Mwz8M478NxzLgenlFIFKJE6CBGJwbbdtMiZNFxEVonIO15NeDQGUrwWS+XsCaVMubPdnQA8//PzGGNo0MCeReitrkqp0irghycRqQZ8AvzFGHMEeB1oBrQD0rDNeIB9Qjsv42N9Q0RkiYgs2bt3b4CiLn73dLiHEYkj+OLmLxDJ/Va3bYNvv3UpMKWUKkBAH5QTkVBscvjA07mQMWa31/w3ga+cl6lAlNfikcDOvOs0xkwEJgJ07NgxXwIprSoFV+L5K57PN33TJoiPh/BwO163rgvBKaWUD4G8i0mAt4F1xph/e01v6FXsOmC1Mz4DuFlEwkSkKdACKJdd7WRmZbIsbRkAzZvDpZfCoUPw97+7HJhSSnkJ5CWmbsDtQK88t7Q+JyK/isgq4HLgIQBjzBrgI2x7T98Cw5z+sMuVY6eP0X5Ce7q/050dR3YgYm93DQ6GN96AX391O0KllLICeRfTj8YYMcbEe9/Saoy53RhzsTO9vzEmzWuZp40xzYwxLY0x3wQqNjdVq1SNFnVacDLjJH+b8zcAYmPh/vshKwsefBBMmblwppQqz/QeGhf8s/c/CQkK4d0V77Jq9yoAxo6F2rVhzhz4/HN341NKKdAE4YoWdVowtONQDIZRs0YBNjn84x92/qOPQma5u7imlCqKzEw4ccJeWfDYuRNWr4aNG0smBm3u2yV/u+xvTFo5ie+2fMfMLTO5otkVDBkCq1bB8OG2TkIpVTKysuDUKd9D48ZQy3la67ffbD3h6dP5ywE89FDOOp94Anbs8L3OP/zBXlYGSEqCW27JX8bzT+KGDXDRRXb84Yfhww9tfzI//xz4/aIJwiV1q9Tl8e6P89j3jzFy1kh6N+1NSEgwb7zhdmRKBVZWlj3AhofnTNu2DY4dyzk4pqfnjMfEQNu2ttyOHfDRR74PuqdP20u1jRrZss8/b58vylvm1Clo3x4+/dSWO34cqlUrON7Jk+H22+34F1/Yg7Qv4eG5E8S0abB+ve+ysbE545mZ9v37EhZmm+TxaNIE2rSBpk0Ljrc4aYJw0QOdH2D6uunc2e5OTJ5nAo2B5cuhQweXglPKhzNn7EHQ+2DrPYwYAVddZctOnmxv3c5bJiMDKlXK+a8boF8/WFtAf5XDhsGrr9rxbdsKPkCDPfv2JIi1a+GHH3yXu+CCnPFKlezfsDDfg3fyaNECrr7ad7nKeboVHjMGjh71XTY6Oqdcx472zCRvmZAQyPNMLc89V7LN82iCcFHl0MosvmdxvierjYH+/eGrr2DhQujc2aUAlcL2WxIRYceDguC11woue9NNOeMnTkBysu9yQUH2e+756jdvbl/7OpjGxeUsFxlp7/Tznl+pUs64JzmATSR//GP+MnkP+iEh9qwm78HYl6uvtoM/br3Vv3Lh4SV3RlBUYsrwPZUdO3Y0S5YscTuMYnM68zSVgu2/M48/Ds8+a/uvTkoKfJtNnh9HGf46lCnyhN3h5u+ld4cbY5umf/JJ+x1s2dJOf+WV/Adcz9C6tb1mD3D4MOzfn79MaKh/B2MVOCKy1BjTsbByegZRCmSZLJ5Z8AzjfxnP8vuWU79afUaPhvfes31Xv/8+DBrkdpSqIklNhT//OeeW66++ykkQf/6zf+uoUcMOquzS21xLgSAJYtGORaQdS+OJeU8AUL06/POfdv5jj9lrmUoF2saNcPfdcOGFNjnUqAGffAKPPOJ2ZMoNmiBKief6PEewBDNx6UTW7V0HwG232UtMaWn2cpNSgfTOO9Cqlf2bmWnrE5Yvh+uvdzsy5RZNEKVE63qtuafDPWSaTB6d/Shg6x083ZO++CJs2eJigKrcMQb27Ml53bs3VKkC995r772fNq30Vp6qkqEJohQZ23Ms1SpV48uNXzI3eS4AXbrAkCH26eoGDdyNT5UPGRn24N+xI/TsmfOkbnS0fVJ34kR7V5FSmiBKkQbVGvBoN3v2MGLmCLKM/eVOmGDvJKla1c3oVFl39Ci8/LI9+N9yCyxbBvv2wdatOWU8t7MqBZogSp2HEx+mUfVGVA6tzIGTB/LNP3rU/geolL9OnLAPmzVpYh9y27bNNt0wYYIdb9bM7QhVaaUJopSpElqFRfcsYv4d86lbJXf3cp9+an/YEye6FJwq9U6dgnnzYPz4nGmVK9vvzqFD0L27vTtp3Tp76TLv079KedPnIEqhyIjIAuft2mUf4b/5ZtsCrKrYjLENPM6ebYf58+0ZQ1CQvYxUq5Z9KG38eHsGkZDgdsSqLNEziFJs/b713PrJrew7sQ+A666Dyy+HAwdso2QVkTH2IS5lPfwwtGtn20D69lubHOLi4IEHcrd1dN11mhxU0QWyT+ooEZkjIutEZI2IPOhMry0is0Rkk/O3ljNdRGSciGwWkVUiUuGbqXtk5iNMXT2Vf8yzHUWI2ErGoCD7H+GaNS4H6IJt2yAqyt5xc9tt9jr6mjW528yvSL77zv698Ub7xH1amm2O+qWX9K43df4CeQaRATxijGkNdAGGiUgb4DHge2NMC+B75zXAVUALZxgCvB7A2MqEZ3s/iyCMXzKeTfs3ARAfD3/6k32Q6aGHKkbbSenpOeNbttine7dvhw8+sPsiLg7q1YNrr7XX2T327LEtjpZnr79uk+S779qG6TQpqOIUyD6p04wxy5zxo8A6oDFwLTDJKTYJGOCMXwtMNtZCoKaINAxUfGVBfP147mx3JxlZGYz+fnT29CeftNeWZ82CL790McASsHu3bf/+o4/s69697SW2lSttE9A332wbhztwwLYXVKVKzrLXX29byoyKgksvtW36/+1v9knhlSvdeT/nwxibGD//3DajvXYtXHaZrWz2ft9KFRtjTMAHIAbYDkQAh/LMO+j8/Qro7jX9e6Cjj3UNAZYAS5o0aWLKu9TDqabyU5UNYzE/bvsxe/q4cca0bGnMnDnFsx17+CmedRWnBx6wcXXrZkxWlu8yWVnG/PabMdOn557eubMxQUE57817+POfc8qtXGnMZZcZc8cdxixfHrC3kgtjMYw9+w7PyDBm6lRjRo0ypk8fY2rXzv0eXn21ZGJV5Q+wxPhx7A74XUwiUg34BPiLMeZI3r4PvIv6mJbvAooxZiIwEWxz38UVZ2nVOKIxI7qO4B/z/8GIWSP4+a6fERGGDrWXV0JD3Y4wcFJT7eUTsJdSCvrqiNgmIfI2C7Fwoe3gJjXV9kuwdav9m5xszyg81q+3t4bOmwcpKfZuII+sLNtBS0iIvZQVG2v7JCju5qozM21vZRs2wGjnZDEoyHZLefBgTrk6dWwnUu3bwyWXFG8MSuUV0AQhIqHY5PCBMcbp4I/dItLQGJPmXELytAaTCkR5LR4J7AxkfGXFyK4jmbB0Akt3LmXV7lW0bdCWkDyfnHfnK+XFk0/aO3FuvBEuvvjc1hEampM8Lr/cd5nevWHGDNtJ08KFtt7C02dBUJBNGN9/n1M+IsImithYuOIKGDjw3GIDm4A+/TTnklFIiK1bCg+32x82zPZP3r69TQyBSE5KFSRgCULsqcLbwDpjzL+9Zs0ABgP/dP5+4TV9uIhMAzoDh40xaYGKryypHlad9697nwtrXUiz2rkfe927F/7v/+yB5q23XAowAObMgTfftAfqQN/SW6cOXHONbeL6t99sncUXX9h2sMBuv1Ure7fU6tW2eYqkJDuI5CSITZtsU9meM40WLWzl+QUX2L+eri0Be2688WoSEmDFCjspOtrWJ5w5k9Nf8z/+Edj3rtRZ+XMd6lwGoDv2Z7AKWOEM/YA62PqFTc7f2k55AV4DtgC/4qP+Ie+QkJAQiMtzZcqmTcaEhtpr0osXn/t6SlMdxNGjxjRtauN54omS2+7tt+fsh4cfLrjc7t3G/PCDrQf6/vuc6dOn+67v8AzJyTllaf9m9vRGjYwZP96YU6cC996U8oafdRDa5WgZY4zhozUfcUWzK6hVuRZgW3p97jlITISffjq3SxClqcvRbdvsHUiZmfDLLyVXz7J1q63r6NPHDkXt5vXgQRuv50xj2zZ7hrdnjz3rOHQop8FFiZkH+1rx0lP1ue8+bfJClSx/uxzVBFHGPPDNA7yy+BVGJI7g+SueB2yn8hddZG8J/eAD/ztL9+ZmgtiyBcaNs88x9Oplp2Vk2Pfj6d+4rMvKyp1w5O6u0GAl5unj7gWlKix/E4Q2tVHGDG47GIBxi8ex9aBtpzkiIqfHuVGj4HgZOuZ8953t6H7cOHj++ZzpISHlJzmAj7ORJklQ6YQrsSjlL00QZUxCowRui7+N05mnefyHx7OnDx5s29rZsQP+9S8XAyyCLVvsg25nztiKXk8f3Eqp0kETRBn0dK+nCQsOY9rqaSzesRiw/6GOG2cvFe3a5XKAfkhOtg3IHTpk7yCaNg3atnU7KqWUN00QZVCTGk34S5e/ALbnOU89UteusHFjYPuLOH7cNlOxbRscO3ZudRavvGI7qfn1V2jZEqZMKXqFsFIq8LQ/iDJqdPfRvLXsLRZsX8D/Nv2Pqy+6GsjpS/jUKfj4Y1vRe+iQ7TvillvOvTG3zEx4+237zMW+fTnTv/kG+va142+9ZZ8fqFPHbs97aNfOPksANpEFB9vK9Kefto3vKaVKH00QZVSN8Bo897vn2H9iP30u7JNvflKSfchq48acaSNHwu9/bx/m6tePfE9jg73sU7WqrcfwVBJ//jk88UTOA10xMfYuowMHcndatHy5bTDPl8sug7lz7XhCAuzcCXXr+i6rlCod9DbXcigjw97NdOgQ1Kxp/0NfudK2/JqRAdWr234DPPfkQ/5nJ7ZssU8Wg61Anj7dPmH8/PO26Qvv22I94+vW2YR04ED+IT3dXkqKiAj8+y8L5Am708zfy+7vT5Vd/t7mqmcQ5cTBkwcJCQqhelh1QkLg3//OX2b3bpg82R6sPcnh5Em44YacMj16wD33QP36OdOuuspeFrrvvvzNSnsnltat7aCUKh80QZQD09dOZ8iXQxjacShP9366wHL169vLTN4+/RS+/jrn9dCh9tZTb3fdVYzBKqXKDL13pByIjIjkYPpB/r3w36QcTinSstdck/uup2uuKebglFJlliaIcqBLZBdujL2R9Ix0xswZU6RlIyLg3ntzXnvXSyilKjZNEOXEs72fJTQolMkrJ7M8bbnb4SilygFNEOXEhbUuZHin4RgMI2eNpCzfnaaUKh00QZQjf+3xV2qG1+T7rd/z7eZv3Q5HKVXGaYIoR2pXrs2YHmPo0LADNcNruh2OUqqMC1iCEJF3RGSPiKz2mjZWRHaIyApn6Oc1b7SIbBaRDSJyZaDiKu8e6PwAv9z7C4lRiW6HopQq4wJ5BvEe0NfH9JeMMe2c4WsAEWkD3AzEOsuMF5HgAMZWboUEhRAk9mM9fvo4gz4bxLq961yOSilVFgUsQRhj5gMH/Cx+LTDNGHPKGLMV2Ax0ClRsFcWLSS8yZdUU4t+I5+HvHuboqaNuh6SUKkPcqIMYLiKrnEtQtZxpjQHvJ7xSnWnqPAztOJT7Eu4jMyuTlxa+RJvxbfhi/Rduh6WUKiNKOkG8DjQD2gFpwIvOdPFR1ud9miIyRESWiMiSvXv3BibKcqJe1Xq8cfUbLBmyhEsaXULqkVQGfDiA6z68rshPXCulKp4STRDGmN3GmExjTBbwJjmXkVKBKK+ikcDOAtYx0RjT0RjTsV69eoENuJzo0LADSXcnMa7vOKpXqs7n6z/nl52/uB2WUqqUK9EEISINvV5eB3jucJoB3CwiYSLSFGgBLC7J2Mq74KBg/tz5z6wdtpZ/9v4n17W6Lnve7mO7XYxMKVVaBfI216lAEtBSRFJF5G7gORH5VURWAZcDDwEYY9YAHwFrgW+BYcaYzEDFVpFFRkTyaPdHEaed7l93/0r0y9HZ8z9e8zEnzpxwKzylVCkSsOa+jTG3+Jj89lnKPw0U3Fa1CogF2xdwJutM9usbp99IjbAa3B5/O/d1vI+4C+JcjE4p5SZ9krqCu/+S+/nl3pz6iBa1W3D41GFe/eVVJq+cnD1d23ZSquLRDoMUHRp2yB7f+OeNrNy1kjeXvck9He7Jnj5i5gimrp5KdM1oLqpzEV0ju9KtSTfa1GuT/WCeUqp80QSh8mnboC2v9ns117Tkw8mkHUsj7VgaC1MXZp9d1AyvyS1xtzD+9+MDFs9XG79i6c6lbD64mf0n9tOuQTsubXIpXaO6UiO8RsC2q1RFpwlC+eXDGz5k59GdJB9KZtXuVfyU8hM/bf+JlCMpnMo4lV1u59GdXP/h9XRv0p1uUd3o1qQbF1S9oMD1GmPYeXQn6RnphASFZA81w2sSFhIGwLebv+W1X17LXuabzd/wLM8SJEH0iO7BnMFzAvfGlarANEEov4QEhdCkRhOa1GhCj+geDO80HIDth7eTkZWRXe7H7T+yaMciFu1YxItJ9jnIFrVb0KlxJ8JDwnnzmjez76B64JsH+Hjtx+w6tivf9l7r9xr3X3I/AI8kPkJEWATNajWjRngNFu9YzI/bf2TJziVUCa2Svcyh9EM0H9ecmJox2UPTmk2zx5vXbp6ddFTpZowhy2RhcP4ak2u8SmiV7O/RsdPHOJN5xmf5sOAwalW2DTZkZGWQeiQ137o841ERUVStZLtU3HVsF3uO7/G57UrBlWjboG12rAtTF3I683S+clkmi+a1m9O0VlMA0o6msSxtWYHv6ZqW11ApuBIAc7bOIe1YWq51GQzGGKJrRtOraa8S+RykLFc+duzY0SxZssTtMMoF57fG+X4djp46ys8pP/NTyk/ZycL7ttmMMRkEB9l2GDu/1ZnFOxZTu3JtaobXJCMrg4ysDM5knqF7k+58etOnZ93WiTMnOHDyAJERkQCs2LWC9hPaF1h+5m0z+V2z3wH2dt4lO5fYJFLLJpHoGtFUDq18fjvAT/KE3eHm76X393cm8wyrdq9iYepCklKTWL5rOSfPnMRgmDRgEj2iewDw7IJneWXxK7kOYp7xqIgoVvxpRfY6o1+OZt+JfT4Ppk/1eorHuj8GwPS10xn48cACY9s7ci91q9QF4IopVzDrt1k+y13f+no+ufETALYe3MqF4y4scJ3f/vFbrmxuG5IePXs0//zpnz7LRdeIJvkvydmv6zxXhwMnfTc793Svp3n80sf9ek/7Ru6jTpU6RXpP50pElhpjOhZWTs8gVLGqHladK5tfmf1DO5N5hpW7V7Ji14p8ZZ//3fM0qNaAFrVbZP83WBRVQqvkOoNoW78taY+kkXwomeRDyWw9uNWOH7bjF9bKOTh8ufFLpqyakmt9QRLEEz2f4K89/lrkWMqiLJPFnuN7SDmcwtZDWwkNCuW61vYByr3H9xL1UhSnMk/5XNY76R89fZS0Y2k+y1WrVC3X62OnjxX4nE1mVs6jT0EShCD2r0i+cW/Vw6pTM7ymz/I1wnLqqEKDQ2lSo0mB6/X+LjWs3pCLL7jY57YbVW+Ua/tdIrtw5NQRn+uNqRmTs85qDbmq+VUFvqfQ4NDsspfHXE7dKnURkex94RlPaJjgc/8Fgp5BKKD4ziDKillbZrF4x+JcCeS3g79hMCwbsoz2De2ZyJAvh/D+qvdpVL0RcRfEEVsv1v69IJaWdVqe8yWr4jyDyMzKZO+JvRw7fczn0Ld5XxpUawDAq4tfZdrqaaQeSWXH0R25Lg92aNiBpUOWAjZ5VH2mKlERUXSJ7EJiZCKdGneyB2IRGlRrkH1APZx+mONnjuc6iHnGgyU4+xIP2AQB+DyYBgcF6x1xJUTPIJQ6i981+1325SaPZxc8y+M/PJ59CQzgTNYZTmacZMvBLWw5uIUvNuS0htslsgtJdycB9iD96bpPibsgjua1m+f6bzDQNh/YTKvXWhU4//tB32cniJTDKfyU8lP2vLpV6hIVEUVMzZhcD0UGSRD7Ru7LviZ/NjXCa/h9N1neMwpVummCUMox+tLRDOs0LNelhjd+/wavXPUKyYeSWbNnDav3rGb13tWs2bOGuHo5B9Sth7Zy4/QbAQgNCqVl3Za0qN2CelXqcUHVCxiSMISoGrY9Su+2rz5b9xkpR1JIPZJKypEUWtZpydieYwHYf2I/vSb34nTmaU5lnOJU5qlc4x8P/Jj+LfsTERZBvSr1qFapGtXDqlOtUrVcg+daPcBd7e+iX4t+REZE0jiiMeEh4QXuD3+SgyrfNEEo5SUiLCLX67CQMMIII+6COOIuiOMmbsqe53159nTmaa6+6GpW71lN8qFkm0j2ZPe2y8DYgdkJ4v9++L/s6dd/dH2u7fVu2jt7XERYtXtVgbGmZ6QD9nr5npF7/Hp/Leu2pGXdln6VVUoThFLnyLtivU29Nnx5y5eAvc6+bu86th3ext7je9lzfA9NajTJLhsWnFNvcfVFVxNZPZKoGlFERUTRrHaz7Hk1wmqw/L7lVAquRFhwGGEhYfnGlQokraRWQMWrpHZbWbjNVZVf/lZS6y0DSimlfNIEoZRSyidNEEoppXzSBKGUUsqnQHY5+o6I7BGR1V7TaovILBHZ5Pyt5UwXERknIptFZJWIdCh4zUoppUpCIM8g3gP65pn2GPC9MaYF8L3zGuAqoIUzDAFeD2BcSiml/BCwBGGMmQ/kbeLwWmCSMz4JGOA1fbKxFgI1RaRhoGJTSilVuJKug6hvjEkDcP56epJpDKR4lUt1puUjIkNEZImILNm7d29Ag1VKqYqstDxJ7autZ59PEBljJgITAURkr4hsO4ft1QX2ncNyJcmVGIvY6rbux/MkYwVKeYwOjbH4lIY4o/0pVNIJYreINDTGpDmXkDwNyFE1I28AAAb5SURBVKQCUV7lIoGdha3MGFPvXIIQkSX+PEXoJo2xeGiMxUNjLD5lJU4o+UtMM4DBzvhg4Auv6YOcu5m6AIc9l6KUUkq5I2BnECIyFegJ1BWRVODvwD+Bj0TkbmA74Ol/72ugH7AZOAHcGai4lFJK+SdgCcIYc0sBs3rnnWBsi4HDAhWLDxNLcFvnSmMsHhpj8dAYi09ZibNst+aqlFIqcLSpDaWUUj5pglBKKeVTuU0QItJXRDY47Ts95mP+Hc5zFCuc4R4XYszXXlWe+a63UeVHjD1F5LDXfvybCzFGicgcEVknImtE5EEfZVzdl37G6Oq+FJFwEVksIiudGJ/wUSZMRD509uMiEYkphTG6/tt24ggWkeUi8pWPea7uR78ZY8rdAAQDW4ALgUrASqBNnjJ3AK+6HGcPoAOwuoD5/YBvsA8SdgEWlcIYewJfubwfGwIdnPHqwEYfn7er+9LPGF3dl86+qeaMhwKLgC55ytwPvOGM3wx8WApjdP237cTxMPBfX5+p2/vR36G8nkF0AjYbY34zxpwGpmHbeypVjO/2qry53kaVHzG6zhiTZoxZ5owfBdaRv6kWV/elnzG6ytk3x5yXoc6Q9y4W7/bUpgO9RYr4/P158DNG14lIJPB74K0Ciri6H/1VXhOEv207/cG53DBdRKJ8zHeb321UuSzROeX/RkRi3QzEOVVvj/3P0lup2ZdniRFc3pfOZZEV2FYOZhljCtyPxpgM4DBQp5TFCO7/tl8GRgFZBcx3fT/6o7wmCH/advoSiDHGxAOzycnmpYnfbVS5aBkQbYxpC7wCfO5WICJSDfgE+Isx5kje2T4WKfF9WUiMru9LY0ymMaYdtrmbTiISl6eI6/vRjxhd/W2LyNXAHmPM0rMV8zGttP22y22CKLRtJ2PMfmPMKeflm0BCCcVWFOfURlVJMsYc8ZzyG2O+BkJFpG5JxyEiodgD7wfGmE99FHF9XxYWY2nZl872DwFzyd+nS/Z+FJEQoAYuXYIsKMZS8NvuBvQXkWTs5e1eIvJ+njKlZj+eTXlNEL8ALUSkqYhUwlYCzfAukOf6c3/sNeHSptS3USUiDTzXTkWkE/Y7tb+EYxDgbWCdMebfBRRzdV/6E6Pb+1JE6olITWe8MtAHWJ+nmHd7ajcAPxinprW0xOj2b9sYM9oYE2mMicEee34wxtyWp5ir+9FfpaW572JljMkQkeHAd9g7mt4xxqwRkSeB/2/vXl6jyMIwDv9egiADbsRNXDgRLwtndLxEwdvSrRdGMRJkouJCDFGzFEX0P1CiCKIoogsHHUZciOLKC2EmijNZCKLoTtSFCmoQdL5ZnBNStNWmY2xbzPtAoOrUqTqnilR9XdVd3+mLiItAl6SVwHtS5O742v1Ueb6qcXkfjvIN5KiqoY9rgW2S3gMDQFsD/tGXAhuB/vxsGmA3MKXQz0Yfy1r62Ohj2QycktRECk7nIuJSxXlzHDgt6QHpvGn7iv2rtY8NP7fLfGPHsSZOtWFmZqW+10dMZmY2Sg4QZmZWygHCzMxKOUCYmVkpBwgzMyvlAGFjVs762TOK9ZvLMnVW1GlRlUy4I6lTsk6nJA/Na3XlAGH2+bpJb+o2wgmgq0Ft2xjhAGEGSPpR0rWc4O2apCm5fJqkXkl/Szog6XVhtV+By7lei6Trku7kvyUlbXRI+lPSZaWxSvYVFjdJOqY0xsGV/JYwkrbmtv+RdF7SDwAR8RZ4nN+4NqsLBwizpIeUDnwOcAY4lMsPAgcjYiGF3E2SpgIvCjl/ngErImI+sL6wfqVFQDswF1gnqTWXzwAOR8RPwEtS8AG4EBELcwK/e8CWwrb6gOWfu8Nmw3GAMEsWkwZ3ATgNLCuU/56nzxbqNwPPC/PjgGOS+nP9WVXauZqTyQ0AFwrtPIqIwRQct4GWPP1zvjPpJwWWYgrwZ8Dk2nbPbOQcIGxMkbRdeShKPn1xHS4HzQAwvjC/C3gK/AK0kkYyrGW7g/PvCmUfGMqTdhLojIjZwP6KNsfnfpjVhQOEjSkRcTgi5ubxBIrpvm8xlDCtHbiRp3sZetxTTKh2n6FP+ZDSNT+JiP9ISfmaqnRhhaSJ+TuG1cDNYbo8AXiSU4W3VyybCYzo109mI+EAYZZ0AZsk/Uu6wO/I5TuBbkl/kR4rvQKIiDfAQ0nTc70jwG+SekkX7jdV2rlBeoR1FzgfEX3D9GsvaeS5q3ycenspaUAcs7pwNlezT8i/GhqIiJDUBmyIiFV52RpgQUTsqXFbHUBrRHR+gX7NA7ojYuNot2VWzXc5HoTZF7QA6MkD+bwENg8uiIg/JDVqHOFJpLsLs7rxHYSZmZXydxBmZlbKAcLMzEo5QJiZWSkHCDMzK+UAYWZmpf4HT/sZN4e+7zgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for regularization parameter according to AIC and BIC and compare the R squared parameters and MSE using train-test-split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7771757392006974\n",
      "Testing r^2: 0.5928443563567276\n",
      "Training MSE: 18.59060166796743\n",
      "Testing MSE: 35.369975534761764\n"
     ]
    }
   ],
   "source": [
    "# Code for baseline model\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Testing r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8217470489000607\n",
      "Testing r^2: 0.8737862152862541\n",
      "Training MSE: 13.382669686034594\n",
      "Testing MSE: 14.1706538134\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from AIC\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y)\n",
    "\n",
    "lasso = Lasso(alpha= model_aic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8193919145812878\n",
      "Testing r^2: 0.8766829981681229\n",
      "Training MSE: 13.559485746918268\n",
      "Testing MSE: 13.845417489296059\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha= model_bic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso Path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-Learn there is a function lasso_path which visualizes the shrinkage of the coefficients while alpha changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston Housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
